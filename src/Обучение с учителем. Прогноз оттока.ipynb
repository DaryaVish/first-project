{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка данных</a></span></li><li><span><a href=\"#Исследование-задачи\" data-toc-modified-id=\"Исследование-задачи-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Исследование задачи</a></span></li><li><span><a href=\"#Борьба-с-дисбалансом\" data-toc-modified-id=\"Борьба-с-дисбалансом-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Борьба с дисбалансом</a></span></li><li><span><a href=\"#Тестирование-модели\" data-toc-modified-id=\"Тестирование-модели-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Тестирование модели</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод:\" data-toc-modified-id=\"Вывод:-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Вывод:</a></span></li></ul></li><li><span><a href=\"#Чек-лист-готовности-проекта\" data-toc-modified-id=\"Чек-лист-готовности-проекта-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист готовности проекта</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \n",
    "\n",
    "Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.\n",
    "\n",
    "Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.\n",
    "\n",
    "Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание данных** \n",
    "\n",
    "Датафрейм содержит исторические данные о поведении клиентов и расторжении договоров с банком:\n",
    "\n",
    "- RowNumber — индекс строки в данных,\n",
    "\n",
    "- CustomerId — уникальный идентификатор клиента,\n",
    "\n",
    "- Surname — фамилия,\n",
    "\n",
    "- CreditScore — кредитный рейтинг,\n",
    "\n",
    "- Geography — страна проживания,\n",
    "\n",
    "- Gender — пол,\n",
    "\n",
    "- Age — возраст,\n",
    "\n",
    "- Tenure — сколько лет человек является клиентом банка,\n",
    "\n",
    "- Balance — баланс на счёте,\n",
    "\n",
    "- NumOfProducts — количество продуктов банка, используемых клиентом,\n",
    "\n",
    "- HasCrCard — наличие кредитной карты,\n",
    "\n",
    "- IsActiveMember — активность клиента,\n",
    "\n",
    "- EstimatedSalary — предполагаемая зарплата.\n",
    "\n",
    "\n",
    "Целевой признак\n",
    "\n",
    "- Exited — факт ухода клиента.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://code.s3.yandex.net/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = map(str.lower, data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {'customerid': 'customer_id', 'creditscore': 'credit_score', 'numofproducts': 'num_of_products', 'hascrcard': 'cr_card', 'isactivemember': 'is_active_member', 'estimatedsalary': 'estimated_salary'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1, random_state=12345).drop(['surname', 'rownumber', 'customer_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tenure'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import math\n",
    "def nan_random(v):\n",
    "    if math.isnan(v):\n",
    "        return randint(0, 10)\n",
    "    else:\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tenure'] = data['tenure'].apply(nan_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tenure'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tenure'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(['exited'], axis=1)\n",
    "target = data['exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_df, target_train, target_df = train_test_split(\n",
    "    features, target, test_size=0.4, random_state=12345, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test, features_valid, target_test, target_valid = train_test_split(\n",
    "    features_df, target_df, test_size=0.5, random_state=12345, stratify=target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['credit_score', 'age', 'balance', 'estimated_salary', 'num_of_products']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])\n",
    "features_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** \n",
    "\n",
    "данные содержат 10 тысяч строк в 14 столбцах. В ходе предобработки я удалила 2 столбца: 'Surname' содержащий фамилии и 'RowNumber' задвоивший порядковый номер строк. Пропуски обнаружены в столбце 'tenure' в количестве почти 10% от отщего числа строк. Я сначала попыталась восстановить их с помощью импутера, но отследила через value_counts, что импутер добавил среднее значение и \"5\" стало на 909 больше, за счет чего сильно изменился баланс. Поэтому я решила просто не учитывать этот столбец в фичах. Если удалить эти строки, то почти 10% данных полеряются и в других столбцах. \n",
    "\n",
    "Применила стандартизацию для уравнения значимости всех признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_frequency = target.value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Комментарий:*** \n",
    "соотношение классов 80:20: данные содержат 80% информации о действующих клиентах банка и 20% об ушедших."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Взвешивание классов***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_rfc_balance = None\n",
    "best_result_rfc_balance = 0\n",
    "\n",
    "for depth in tqdm(range(3, 50, 1)):\n",
    "    \n",
    "    for est in range(50, 250, 50):\n",
    "        model = RandomForestClassifier(class_weight='balanced', random_state=12345, max_depth=depth, n_estimators=est, criterion='gini') \n",
    "        model.fit(features_train, target_train) \n",
    "        predictions = model.predict(features_valid) \n",
    "        result = f1_score(target_valid, predictions) \n",
    "        if result > best_result_rfc_balance:\n",
    "            best_model_rfc_balance = model\n",
    "            best_result_rfc_balance = result\n",
    "print(\"f1 лучшей модели:\", best_result_rfc_balance)\n",
    "print(\"Наилучшая модель:\", best_model_rfc_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Oversample***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 3\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_frequency = target_upsampled.value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_upsample_model = None\n",
    "best_upsample_result = 0\n",
    "\n",
    "for depth in tqdm(range(3, 50, 1)):\n",
    "    \n",
    "    for est in range(50, 250, 50):\n",
    "        model = RandomForestClassifier(random_state=12345, max_depth=depth, n_estimators=est, criterion='gini') \n",
    "        model.fit(features_upsampled, target_upsampled) \n",
    "        predictions = model.predict(features_valid) \n",
    "        result = f1_score(target_valid, predictions) \n",
    "        if result > best_upsample_result:\n",
    "            best_upsample_model = model\n",
    "            best_upsample_result = result\n",
    "print(\"f1 лучшей модели:\", best_upsample_result)\n",
    "print(\"Наилучшая модель:\", best_upsample_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(target_valid, (best_upsample_model.predict(features_valid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_upsample_lr = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model_upsample_lr.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model_upsample_lr.predict(features_valid)\n",
    "print(\"F1 после баланса:\", f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** \n",
    "после работы над дисбалансом классов метрика f1 моделей возрасла. Я применила взвешивание классов и upsampling для модели логистической регресии и случайного леса. Лучший результат показала модель RandomForest upsampling, ее и оставим для тестирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = best_upsample_model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1:\", f1_score(target_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(target_test, (best_upsample_model.predict(features_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Комментарий***\n",
    "модель справляется с положительными и отрицательными ответами, но в FN и FP все еще попадает много."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(target_test, best_upsample_model.predict_proba(features_test)[:,1]) \n",
    "\n",
    "plt.figure()\n",
    "plt.title('ROC-кривая')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlim([0.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_roc = roc_auc_score(target_test, best_upsample_model.predict_proba(features_test)[:, 1])\n",
    "print(auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**  \n",
    "\n",
    "у модели достаточно высокий roc_auc: 0.85, она неплохо справляется с класификацией положительных и отрицательных ответов, f1 достигает 0.61."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_balance = best_model_rfc_balance.predict(features_test)\n",
    "print(\"F1:\", f1_score(target_test, test_predictions_balance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(target_test, (best_model_rfc_balance.predict(features_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(target_test, best_model_rfc_balance.predict_proba(features_test)[:,1]) \n",
    "\n",
    "plt.figure()\n",
    "plt.title('ROC-кривая')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlim([0.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_roc = roc_auc_score(target_test, best_model_rfc_balance.predict_proba(features_test)[:, 1])\n",
    "print(auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:\n",
    "\n",
    "Датафрейм содержит исторические данные - каждый объект в наборе данных это информация о поведении одного клиента. Целевой признак - факт ухода клиента, данные содержат признаки, основываясь на которых модель должна предположить расторгнет ли пользователь договор с банком. Среди признаков: кредитный рейтинг, страна проживания, пол и возраст, баланс на счёте, количество продуктов банка, используемых клиентом, наличие кредитной карты, активность клиента и предполагаемая зарплата. \n",
    "\n",
    "\n",
    "В датафрейме хранятся 10 тысяч строк в 14 столбцах, данные были разбиты на 3 выборки в соотношении 60:20:20 - обучающая, валидационная и тестовая.\n",
    " \n",
    "\n",
    "- соотношение классов 80:20: 80% информации о действующих клиентах банка и 20% об ушедших. \n",
    "\n",
    "\n",
    "Без баланса классов модель LogisticRegression находит лучше всего TN и FN. Почти все положительные ответы попадают в FN. \n",
    "\n",
    "- модель LogisticRegression f1 за счет баланса повысилась с 0.3 до 0.48;\n",
    "- после баланса модель стала стала лучше находить единицы, но начала путать нули: появилось очень много FP ответов, до баланса их было всего 55, а теперь 470. FN до баланса было 323, а после стало 137. TP до баланса было 88, а после 270;\n",
    "- среднегармоническое полноты и точности модели RF после баланса возросло с 0.56 до 0.61.\n",
    "\n",
    "После работы над дисбалансом классов метрика f1 моделей возрасла. Я применила взвешивание классов для модели логистической регресии, для модели случайного леса лучший результат показала техника upsampling. \n",
    "\n",
    " \n",
    "Для работы с тестовой выборкой были взяты модели с наилушим показателем f1 - RF после баланса. На тестовой выборке roc_auc: 0.85, f1 достигает 0.61\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист готовности проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставьте 'x' в выполненных пунктах. Далее нажмите Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Выполнен шаг 1: данные подготовлены\n",
    "- [x]  Выполнен шаг 2: задача исследована\n",
    "    - [x]  Исследован баланс классов\n",
    "    - [x]  Изучены модели без учёта дисбаланса\n",
    "    - [x]  Написаны выводы по результатам исследования\n",
    "- [x]  Выполнен шаг 3: учтён дисбаланс\n",
    "    - [x]  Применено несколько способов борьбы с дисбалансом\n",
    "    - [x]  Написаны выводы по результатам исследования\n",
    "- [x]  Выполнен шаг 4: проведено тестирование\n",
    "- [x]  Удалось достичь *F1*-меры не менее 0.59\n",
    "- [x]  Исследована метрика *AUC-ROC*"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
